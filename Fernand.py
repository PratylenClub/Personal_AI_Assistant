import osimport speech_recognition as srimport pyttsximport timeimport timestringimport gensimimport pyowmfrom Functions import (    get_hour,    get_date,    get_weather,    get_temperatures,    set_a_reminder    )from Assistant import personal_assistant,ACTION,PARAMETERS# Weather assistantkey = open("Keys/OWM_KEY.txt","r").read()owm = pyowm.OWM(key,language='en')# Word2Vec# Links for other projects https://github.com/3Top/word2vec-api#where-to-get-a-pretrained-models# https://github.com/facebookresearch/fastText/blob/master/pretrained-vectors.md?utm_campaign=buffer&utm_content=buffer0df9b&utm_medium=social&utm_source=linkedin.comprint "loading brain"word2vec_model = gensim.models.KeyedVectors.load_word2vec_format("Models/glove.6B.50d.bin",binary=False)print "brain loaded"# Synthesizerpyttx_engine = pyttsx.init()# Speech recognitionspeech_recognizer = sr.Recognizer()speech_recognition_microphone = sr.Microphoneactions_dict = {"hour" : {ACTION: get_hour, PARAMETERS: (time,)},                "date" : {ACTION: get_date, PARAMETERS: (time,)},                "weather": {ACTION: get_weather, PARAMETERS: (owm,)},                "temperature": {ACTION: get_temperatures, PARAMETERS:(owm,)}                }trigger_dict = {"hour": ["hour", "time"],                "date": ["date", "day"],                "weather": ["weather", "climate", "actual temperature", "current temperature"],                "temperature": ["forecast", "temperature latter"]                }confirmation_threshold = 0.3centroid_shelve_file_name = "centroids_shelve"# Personal Assistantfernand = personal_assistant(word2vec_model,                             pyttx_engine,                             speech_recognition_microphone,                             speech_recognizer,                             actions_dict,                             trigger_dict,                             confirmation_threshold,                             centroid_shelve_file_name)for i in range(10):    print i    fernand.interactive_step()